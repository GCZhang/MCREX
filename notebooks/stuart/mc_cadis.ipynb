{
 "metadata": {
  "name": "",
  "signature": "sha256:919e13acba5d523b3254ad458904b001b553edb0c2be07409d4f3cf08de57377"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext autoreload"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The autoreload extension is already loaded. To reload it, use:\n",
        "  %reload_ext autoreload\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%autoreload 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "CADIS Variance Reduction for Forward Monte Carlo"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "An importance map, $\\phi$, may be used to describe how important a particular region of the problem is to Monte Carlo calculation. Using this importance map we can the prescribe a variance reduction scheme that favors regions of high importance while attempting to minimize the work performed in regions of low importance. To do this, we need to prescribe the behaviour of a Monte Carlo history is it moves between regions of different importance."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "CADIS"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We start by defining the forward linear problem:\n",
      "\\begin{equation}\n",
      "    \\mathbf{A} \\mathbf{x} = \\mathbf{b}\n",
      "\\end{equation}\n",
      "and the equation adjoint to it:\n",
      "\\begin{equation}\n",
      "    \\mathbf{A^T} \\mathbf{y} = \\mathbf{d}\n",
      "\\end{equation}\n",
      "with $\\mathbf{y}$ the adjoint solution. We can then define:\n",
      "\\begin{equation}\n",
      "    R = <\\mathbf{x},\\mathbf{d}> = <\\mathbf{y},\\mathbf{b}>\n",
      "\\end{equation}\n",
      "such that $R$ is the response which we want to compute. If we pick $\\mathbf{d} = \\boldsymbol{\\delta_{j}}$ where $\\delta_{j}$ is a vector of delta functions such that the $i^{th}$ component is ${\\boldsymbol{\\delta_{j}}}_i = \\delta_{ij}$ then the response we are optimizing for is the $j^{th}$ component of the solution:\n",
      "\\begin{equation}\n",
      "    R = \\mathbf{x}_j \\:.\n",
      "\\end{equation}\n",
      "Using an effective transport biasing procedure to construct a set of weight windows to for variance reduction. The lower weight window bound in a given state $i$ is:\n",
      "\\begin{equation}\n",
      "    \\mathbf{W_l}_i = \\Bigg( \\frac{|R|}{|\\mathbf{y}_i|} \\frac{2}{C_u + 1} \\Bigg )\n",
      "\\end{equation}\n",
      "where $C_u$ is a user-defined parameter for the width of the window typically defined between 2 and 10. The upper bound of the weight window is then:\n",
      "\\begin{equation}\n",
      "    \\mathbf{W_u}_i = C_u \\mathbf{W_l}_i\n",
      "\\end{equation}\n",
      "and the survival weight for roulette:\n",
      "\\begin{equation}\n",
      "    \\mathbf{W_s}_i = \\frac{ \\mathbf{W_l}_i + \\mathbf{W_u}_i } { 2 }\n",
      "\\end{equation}"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy\n",
      "\n",
      "def computeWeightWindows( y, R, c_u ):\n",
      "    size = len(y)\n",
      "    w_l = numpy.zeros( size )\n",
      "    w_u = numpy.zeros( size )\n",
      "    w_s = numpy.zeros( size )\n",
      "    for i in xrange(size):\n",
      "        w_l[i] = 2.0 * abs(R) / ( abs(y[i])*(c_u + 1 ) )\n",
      "        w_u[i] = c_u * w_l[i]\n",
      "        w_s[i] = (w_l[i] + w_u[i]) / 2.0\n",
      "    return (w_l,w_u,w_s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Russian Roulette"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random\n",
      "\n",
      "def roulette( w, w_s ):\n",
      "    rn = random.random()\n",
      "    return rn > (w/w_s)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Splitting"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "\n",
      "def split( w, w_l, w_u, w_s ):\n",
      "    rn = random.random()\n",
      "    nu = w / w_s\n",
      "    n = int( math.floor(nu) )\n",
      "    if ( rn < 1 + n - nu ):\n",
      "        n_split = n\n",
      "    else:\n",
      "        n_split = n + 1\n",
      "    w_split = w / n_split\n",
      "    return (n_split, w_split)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Non-Analog Solution"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Non-Analog Forward Random Walk"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import mc_tools\n",
      "\n",
      "def doOneNonAnalogHistory( b, starting_state, C, W, x, sigma, w_c, w_l, w_u, w_s ):\n",
      "\n",
      "    # Make a set of stacks to keep track of split histories.\n",
      "    history_stack = []\n",
      "    weight_stack = []\n",
      "    hw_stack = []\n",
      "    \n",
      "    # Initialize the state of the history.\n",
      "    tally = 0.0\n",
      "    history_stack.append(starting_state)\n",
      "    weight_stack.append( 1.0 )\n",
      "    hw_stack.append( w_s[starting_state] )\n",
      "\n",
      "    # Run all histories in the stack.\n",
      "    while len(history_stack) > 0:\n",
      "        state = history_stack.pop()\n",
      "        weight = weight_stack.pop()\n",
      "        hw = hw_stack.pop()\n",
      "\n",
      "        # Run histories until the cutoff.\n",
      "        while abs(weight) > w_c:\n",
      "\n",
      "            # Tally.\n",
      "            weight_frac = hw / w_s[starting_state]\n",
      "            tally = tally + weight_frac*weight*b[state]\n",
      "            \n",
      "            # Process a transition.\n",
      "            new_state = mc_tools.sampleMatrixCDF( state, random.random(), C )\n",
      "            weight = weight * W[state][new_state]\n",
      "            state = new_state\n",
      "\n",
      "            # Roulette if below weight window.\n",
      "            if (hw < w_l[state]):\n",
      "\n",
      "                # If it was killed, set the weight to zero.\n",
      "                if ( roulette(hw,w_s[state]) ):\n",
      "                    weight = 0.0\n",
      "\n",
      "                # If it survived set the weight to the survival weight.\n",
      "                else:\n",
      "                    hw = w_s[state]\n",
      "\n",
      "            # Split if above weight window\n",
      "            elif (hw > w_u[state]):\n",
      "\n",
      "                # Compute the number of new histories and push them\n",
      "                # onto the stack.\n",
      "                n_split, w_split = split( hw, w_l[state], w_u[state], w_s[state] )\n",
      "                for j in xrange(n_split):\n",
      "                    history_stack.append(state)\n",
      "                    weight_stack.append(weight)\n",
      "                    hw_stack.append(w_split)\n",
      "\n",
      "                # End the current history in leiu of the new histories\n",
      "                # from the split.\n",
      "                weight = 0.0\n",
      "        \n",
      "    # Return the mean and variance estimates.\n",
      "    x = x + tally\n",
      "    sigma = sigma + tally*tally\n",
      "    return (x, sigma)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Non-analog Monte Carlo Linear Solver"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using the modified sampling procedure we can now write a non-analog Monte Carlo solver for linear systems using the forward method. The inputs are the linear operator, the right hand side, the residual, the weight cutoff, and the number of histories."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import mc_data\n",
      "import array_tools\n",
      "\n",
      "def nonAnalogMC( A, b, w_c, np, c_u, state ):\n",
      "    \n",
      "    # Make the standard Monte Carlo data structures.\n",
      "    size = len(A)\n",
      "    H = mc_data.makeIterationMatrix( A )\n",
      "    P = numpy.zeros( (size,size) )\n",
      "    for i in xrange(size):\n",
      "        row_sum = 0.0\n",
      "        for j in xrange(size):\n",
      "            row_sum += abs(H[i][j])\n",
      "        for j in xrange(size):\n",
      "            P[i][j] = abs(H[i][j]) / row_sum\n",
      "    C = mc_data.makeCDFMatrix( P )\n",
      "    W = numpy.zeros( (size,size) )\n",
      "    for i in xrange(size):\n",
      "        for j in xrange(size):\n",
      "            if P[i][j] > 0.0:\n",
      "                W[i][j] = H[i][j] / P[i][j]\n",
      "    \n",
      "    # Solve the adjoint problem.\n",
      "    d = numpy.zeros( size )\n",
      "    d[state] = 1.0\n",
      "    A_T = array_tools.matrixTranspose(A)\n",
      "    y = numpy.linalg.solve( A_T, d )\n",
      "    \n",
      "    # Compute the response.\n",
      "    R = numpy.dot(y,b)\n",
      "    \n",
      "    # Build the weight windows.\n",
      "    w_l, w_u, w_s = computeWeightWindows( y, R, c_u )\n",
      "    \n",
      "    # Solve the problem with non-analog Monte Carlo.\n",
      "    x = 0.0\n",
      "    sigma = 0.0\n",
      "    for i in xrange(np):\n",
      "        x, sigma = doOneNonAnalogHistory( b, state, C, W, x, sigma, w_c, w_l, w_u, w_s )\n",
      "\n",
      "    # Normalize the mean and variance tallies.    \n",
      "    x = x / np\n",
      "    sigma = (sigma / np - x*x)/np\n",
      "    return (x, sigma)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Analog Solution"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Analog Forward Random Walk"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def doOneAnalogHistory( b, starting_state, C, W, x, sigma, w_c ):\n",
      "\n",
      "    # Initialize the state of the history.\n",
      "    tally = 0.0\n",
      "    state = starting_state\n",
      "    weight = 1.0\n",
      "\n",
      "    # Run histories until the cutoff.\n",
      "    while abs(weight) > w_c:\n",
      "\n",
      "        # Process a transition\n",
      "        tally = tally + weight*b[state]\n",
      "        new_state = mc_tools.sampleMatrixCDF( state, random.random(), C )\n",
      "        weight = weight * W[state][new_state]\n",
      "        state = new_state\n",
      "        \n",
      "    # Return the mean and variance estimates.\n",
      "    x = x + tally\n",
      "    sigma = sigma + tally*tally\n",
      "    return (x, sigma)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Analog Monte Carlo Linear Solver"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import mc_data\n",
      "import array_tools\n",
      "\n",
      "def analogMC( A, b, w_c, np, state ):\n",
      "    \n",
      "    # Make the standard Monte Carlo data structures.\n",
      "    size = len(A)\n",
      "    H = mc_data.makeIterationMatrix( A )\n",
      "    P = numpy.zeros( (size,size) )\n",
      "    for i in xrange(size):\n",
      "        row_sum = 0.0\n",
      "        for j in xrange(size):\n",
      "            row_sum += abs(H[i][j])\n",
      "        for j in xrange(size):\n",
      "            P[i][j] = abs(H[i][j]) / row_sum\n",
      "    C = mc_data.makeCDFMatrix( P )\n",
      "    W = numpy.zeros( (size,size) )\n",
      "    for i in xrange(size):\n",
      "        for j in xrange(size):\n",
      "            if P[i][j] > 0.0:\n",
      "                W[i][j] = H[i][j] / P[i][j]\n",
      "    \n",
      "    # Solve the problem with analog Monte Carlo.\n",
      "    x = 0.0\n",
      "    sigma = 0.0\n",
      "    for i in xrange(np):\n",
      "        x, sigma = doOneAnalogHistory( b, state, C, W, x, sigma, w_c )\n",
      "\n",
      "    # Normalize the mean and variance tallies.    \n",
      "    x = x / np\n",
      "    sigma = (sigma / np - x*x)/np\n",
      "    return (x, sigma)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Model Problem"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We solve the following linear problem on one-dimension:\n",
      "\\begin{equation}\n",
      "    \\nabla^2 \\mathbf{u} - D \\mathbf{u} = \\mathbf{f}\n",
      "\\end{equation}\n",
      "with $\\mathbf{u} \\in \\mathbf{R}^N$ the solution variable, $\\mathbf{f} \\in \\mathbb{R}^N$ the forcing term, and D a scalar. We discretize with a cell-centered finite difference with mesh size h:\n",
      "\\begin{equation}\n",
      "    \\frac{1}{h^2}(u_{i-1} - 2u_i + u_{i+1}) - D u_{i-1} = f_i\n",
      "\\end{equation}\n",
      "The boundary conditions on the left are:\n",
      "\\begin{equation}\n",
      "    \\frac{1}{h^2}(u_{-1} - 2u_0 + u_{1}) -D u_0 = f_0\n",
      "\\end{equation}\n",
      "On a cell-centered grid we have:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "    |-------x------|-------x------|------x------|\n",
      "u(-1/2)    u(0)          u(1)           u(2)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We set $u_{-1/2} = 0$ so that\n",
      "\\begin{equation}\n",
      "\\frac{1}{h^2}(-3u_0 + u_1) - D u_0= f_0\n",
      "\\end{equation}\n",
      "\n",
      "This gives the following linear operator:\n",
      "\\begin{equation}\n",
      "    \\nabla^2 = \\frac{1}{h^2}\n",
      "    \\begin{bmatrix}\n",
      "        -3-D & 1 & & & & & \\\\\n",
      "         1 & -2-D & 1 & & & & \\\\\n",
      "           & 1 & -2-D & 1 & & & \\\\\n",
      "           & & & \\cdots & & & \\\\\n",
      "           & & & & 1 & -2-D & 1 \\\\\n",
      "           & & & & & 1 & -3-D \\\\\n",
      "    \\end{bmatrix}\n",
      "\\end{equation}\n",
      "\n",
      "We will construct the diagonally-scaled operators on each grid next:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "grid_size = 100\n",
      "h = 1.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import array_tools\n",
      "import mc_data\n",
      "\n",
      "D = 0.1\n",
      "\n",
      "A = array_tools.makePoissonOperator( grid_size, h, D )\n",
      "diag = array_tools.getInvDiag( A )\n",
      "\n",
      "A = array_tools.leftScaleMatrix( A, diag )\n",
      "\n",
      "H = mc_data.makeIterationMatrix( A )\n",
      "eval_H, evec_H = numpy.linalg.eig(H)\n",
      "spec_rad_H = max(sorted(abs(i) for i in eval_H))\n",
      "print \"rho(H):\", spec_rad_H"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "rho(H): 0.951911241344\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Forcing Term"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next make a forcing term. Choose a forcing term of unity to make it simple to define on each grid. We apply the diagonal scaling here as well. Set use_random to true to add some randomness to the right hand side."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "use_random = True\n",
      "f = numpy.zeros( grid_size )\n",
      "for i in xrange(grid_size):\n",
      "    if use_random:\n",
      "        f[i] = 1.0 + random.random() * random.random()\n",
      "    else:\n",
      "        f[i] = 1.0\n",
      "f = array_tools.scaleVector( f, diag )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Reference Solution"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ref = numpy.linalg.solve(A,f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Monte Carlo Solution"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Set the weight cutoff and number of histories. Randomly choose the state to solve for."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w_c = 1.0e-2\n",
      "np = 1000\n",
      "state = int( grid_size * random.random() )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Analog Monte Carlo"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "\n",
      "start = time.time()\n",
      "x_analog, sigma_analog = analogMC( A, f, w_c, np, state )\n",
      "end = time.time()\n",
      "time_analog = end - start\n",
      "print \"Analog Time:\", time_analog"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Analog Time: 2.97192311287\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Monte Carlo with CADIS"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import variance_reduction\n",
      "\n",
      "c_u = 2.0\n",
      "\n",
      "start = time.time()\n",
      "x_na, sigma_na = nonAnalogMC( A, f, w_c, np, c_u, state )\n",
      "end = time.time()\n",
      "time_na = end - start\n",
      "print \"Non-Analog Time:\", time_na"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Non-Analog Time: 1.4178109169\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Analysis"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compute the solution errors and figure of merit."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Solution\", state\n",
      "print \"Reference: \", ref[state]\n",
      "print \"Analog:    \", x_analog, sigma_analog\n",
      "print \"Non-Analog:\", x_na, sigma_na\n",
      "print\n",
      "print \"Error\"\n",
      "print \"Analog:    \", abs((ref[state]-x_analog) / ref[state])\n",
      "print \"Non-Analog:\", abs((ref[state]-x_na) / ref[state])\n",
      "\n",
      "print\n",
      "print \"Figure of Merit\"\n",
      "print \"Analog:    \", 1.0 / (sigma_analog*time_analog)\n",
      "print \"Non-Analog:\", 1.0 / (sigma_na*time_na)\n",
      "print \"Relative:  \", (sigma_analog*time_analog)/(sigma_na*time_na)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Solution 97\n",
        "Reference:  6.9609485528\n",
        "Analog:     6.76135575008 0.0113149278018\n",
        "Non-Analog: 6.21960809074 0.107831552303\n",
        "\n",
        "Error\n",
        "Analog:     0.0286732190603\n",
        "Non-Analog: 0.106499919722\n",
        "\n",
        "Figure of Merit\n",
        "Analog:     29.7379237334\n",
        "Non-Analog: 6.54087465654\n",
        "Relative:   0.219950616431\n"
       ]
      }
     ],
     "prompt_number": 53
    }
   ],
   "metadata": {}
  }
 ]
}